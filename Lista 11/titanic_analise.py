# -*- coding: utf-8 -*-
"""Titanic_Analise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1soDvt3bS1TOjMk2pUdFut7cJ2UW0Tc0-

# ğŸ›³ï¸ AnÃ¡lise de Dados do Titanic com Machine Learning
### ğŸ‘©â€ğŸ’» Autora: Ana Carolina Machado
### ğŸ“… Data: 30 de maio de 2025

## ğŸ” 1. IntroduÃ§Ã£o
Neste notebook, aplicaremos tÃ©cnicas de Machine Learning para prever a sobrevivÃªncia dos passageiros do Titanic com base em um conjunto de dados histÃ³ricos. Utilizaremos modelos como **Random Forest** e **MLPClassifier**, alÃ©m de realizar ajustes com **GridSearchCV** para encontrar a melhor configuraÃ§Ã£o de hiperparÃ¢metros.
"""

# ğŸ“¥ 2. ImportaÃ§Ã£o de Bibliotecas e Carregamento dos Dados
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score

os.chdir(os.path.dirname(os.path.abspath(__file__)))

# Carregamento dos dados
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

"""## ğŸ“Š 3. EstatÃ­sticas Descritivas"""

train_df.describe(include='all')
print(train_df.isnull().sum())
print(test_df.isnull().sum())

"""## ğŸ§¹ 4. Tratamento de Dados"""

# Preenchendo valores ausentes
train_df["Embarked"].fillna(train_df["Embarked"].mode()[0], inplace=True)
test_df["Age"] = test_df["Age"].fillna(test_df["Age"].median())
test_df["Fare"] = test_df["Fare"].fillna(test_df["Fare"].median())

"""## ğŸ§  5. Treinamento de Modelos"""

# SeleÃ§Ã£o de colunas relevantes
feature_columns = ['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch', 'Embarked']
# CodificaÃ§Ã£o de variÃ¡veis categÃ³ricas
train_df = pd.get_dummies(train_df, columns=['Sex', 'Embarked'], drop_first=True)
test_df = pd.get_dummies(test_df, columns=['Sex', 'Embarked'], drop_first=True)

X = train_df[feature_columns + ['Sex_male', 'Embarked_Q', 'Embarked_S']]
y = train_df['Survived']

# NormalizaÃ§Ã£o pode ser Ãºtil para MLP
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
print("=== Random Forest ===")
print(classification_report(y_test, rf_pred))

"""## ğŸ” ClassificaÃ§Ã£o com Backpropagation (Rede Neural Simples)

Nesta seÃ§Ã£o, implementamos uma rede neural simples com uma camada oculta usando o algoritmo de **Backpropagation**. A rede Ã© treinada para prever se um passageiro sobreviveu com base em atributos como classe, sexo, idade e tarifa.

- A funÃ§Ã£o de ativaÃ§Ã£o utilizada Ã© a **sigmoide**, adequada para problemas de classificaÃ§Ã£o binÃ¡ria.
- A funÃ§Ã£o de perda Ã© o erro quadrÃ¡tico mÃ©dio (MSE), embora a entropia cruzada seja mais comum em classificaÃ§Ãµes â€” aqui optamos pela simplicidade.
- O treinamento Ã© feito por 1000 Ã©pocas com taxa de aprendizado 0.1.

A rede possui:
- Uma camada de entrada com o mesmo nÃºmero de neurÃ´nios que os atributos de entrada
- Uma camada oculta com 3 neurÃ´nios
- Uma camada de saÃ­da com 1 neurÃ´nio, que retorna a probabilidade de sobrevivÃªncia.

"""

import numpy as np
from sklearn.metrics import accuracy_score

# FunÃ§Ã£o de ativaÃ§Ã£o sigmoide e sua derivada
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivada(x):
    return x * (1 - x)

# Estrutura da rede
n_entrada = X_train.shape[1]   # nÃºmero de atributos
n_oculta = 3                   # nÃºmero de neurÃ´nios na camada oculta
n_saida = 1                    # saÃ­da binÃ¡ria (sobreviveu ou nÃ£o)

# InicializaÃ§Ã£o dos pesos
np.random.seed(42)
pesos_entrada_oculta = np.random.uniform(-1, 1, (n_entrada, n_oculta))
bias_oculta = np.zeros((1, n_oculta))

pesos_oculta_saida = np.random.uniform(-1, 1, (n_oculta, n_saida))
bias_saida = np.zeros((1, n_saida))

# HiperparÃ¢metros
epocas = 1000
taxa_aprendizado = 0.1

# Treinamento
for epoca in range(epocas):
    # Forward pass
    entrada_oculta = np.dot(X_train, pesos_entrada_oculta) + bias_oculta
    saida_oculta = sigmoid(entrada_oculta)

    entrada_saida = np.dot(saida_oculta, pesos_oculta_saida) + bias_saida
    saida_final = sigmoid(entrada_saida)

    # CÃ¡lculo do erro
    erro = y_train - saida_final

    # Backpropagation
    delta_saida = erro * sigmoid_derivada(saida_final)
    erro_oculta = delta_saida.dot(pesos_oculta_saida.T)
    delta_oculta = erro_oculta * sigmoid_derivada(saida_oculta)

    # AtualizaÃ§Ã£o dos pesos e bias
    pesos_oculta_saida += saida_oculta.T.dot(delta_saida) * taxa_aprendizado
    bias_saida += np.sum(delta_saida, axis=0, keepdims=True) * taxa_aprendizado

    pesos_entrada_oculta += X_train.T.dot(delta_oculta) * taxa_aprendizado
    bias_oculta += np.sum(delta_oculta, axis=0, keepdims=True) * taxa_aprendizado

    # Exibir erro ocasionalmente
    if epoca % 100 == 0:
        erro_medio = np.mean(np.abs(erro))
        print(f"Ã‰poca {epoca} - Erro mÃ©dio: {erro_medio:.4f}")

# Teste
entrada_oculta_teste = np.dot(X_test, pesos_entrada_oculta) + bias_oculta
saida_oculta_teste = sigmoid(entrada_oculta_teste)

entrada_saida_teste = np.dot(saida_oculta_teste, pesos_oculta_saida) + bias_saida
saida_final_teste = sigmoid(entrada_saida_teste)

# AvaliaÃ§Ã£o
predicoes = (saida_final_teste > 0.5).astype(int)
acuracia = accuracy_score(y_test, predicoes)

print(f"\nğŸ¯ AcurÃ¡cia no conjunto de teste: {acuracia * 100:.2f}%")

"""## ğŸ› ï¸ 6. OtimizaÃ§Ã£o com GridSearchCV"""

param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [4, 6, 8],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}
grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)
grid.fit(X_train, y_train)
print("ğŸŒŸ Melhor combinaÃ§Ã£o de hiperparÃ¢metros:")
print(grid.best_params_)

best_rf = grid.best_estimator_
best_rf_pred = best_rf.predict(X_test)
print("ğŸ“Š RelatÃ³rio de classificaÃ§Ã£o (Random Forest ajustado):")
print(classification_report(y_test, best_rf_pred))

"""## ğŸ“ 7. GeraÃ§Ã£o do Arquivo de SubmissÃ£o"""

X_final_test = test_df[feature_columns + ['Sex_male', 'Embarked_Q', 'Embarked_S']]
X_final_test = scaler.transform(X_final_test)

submission = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Survived': best_rf.predict(X_final_test)
})
submission.to_csv('submission.csv', index=False)
print("âœ… Arquivo 'submission.csv' gerado com sucesso!")

"""## ğŸ“ˆ 8. VisualizaÃ§Ãµes"""

sns.countplot(data=train_df, x='Survived', hue='Pclass')
plt.title("SobrevivÃªncia por Classe")
plt.tight_layout()
plt.show()

"""## âœ… ConclusÃ£o
- O modelo Random Forest com hiperparÃ¢metros ajustados obteve uma **acurÃ¡cia de 81%**.
- O MLPClassifier tambÃ©m apresentou bons resultados, mas com desempenho inferior.
- O arquivo de submissÃ£o foi gerado com sucesso e pode ser enviado Ã  plataforma de avaliaÃ§Ã£o.
"""