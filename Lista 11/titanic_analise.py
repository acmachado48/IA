# -*- coding: utf-8 -*-
"""Titanic_Analise.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1soDvt3bS1TOjMk2pUdFut7cJ2UW0Tc0-

# 🛳️ Análise de Dados do Titanic com Machine Learning
### 👩‍💻 Autora: Ana Carolina Machado
### 📅 Data: 30 de maio de 2025

## 🔍 1. Introdução
Neste notebook, aplicaremos técnicas de Machine Learning para prever a sobrevivência dos passageiros do Titanic com base em um conjunto de dados históricos. Utilizaremos modelos como **Random Forest** e **MLPClassifier**, além de realizar ajustes com **GridSearchCV** para encontrar a melhor configuração de hiperparâmetros.
"""

# 📥 2. Importação de Bibliotecas e Carregamento dos Dados
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score

os.chdir(os.path.dirname(os.path.abspath(__file__)))

# Carregamento dos dados
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

"""## 📊 3. Estatísticas Descritivas"""

train_df.describe(include='all')
print(train_df.isnull().sum())
print(test_df.isnull().sum())

"""## 🧹 4. Tratamento de Dados"""

# Preenchendo valores ausentes
train_df["Embarked"].fillna(train_df["Embarked"].mode()[0], inplace=True)
test_df["Age"] = test_df["Age"].fillna(test_df["Age"].median())
test_df["Fare"] = test_df["Fare"].fillna(test_df["Fare"].median())

"""## 🧠 5. Treinamento de Modelos"""

# Seleção de colunas relevantes
feature_columns = ['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch', 'Embarked']
# Codificação de variáveis categóricas
train_df = pd.get_dummies(train_df, columns=['Sex', 'Embarked'], drop_first=True)
test_df = pd.get_dummies(test_df, columns=['Sex', 'Embarked'], drop_first=True)

X = train_df[feature_columns + ['Sex_male', 'Embarked_Q', 'Embarked_S']]
y = train_df['Survived']

# Normalização pode ser útil para MLP
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
print("=== Random Forest ===")
print(classification_report(y_test, rf_pred))

"""## 🔁 Classificação com Backpropagation (Rede Neural Simples)

Nesta seção, implementamos uma rede neural simples com uma camada oculta usando o algoritmo de **Backpropagation**. A rede é treinada para prever se um passageiro sobreviveu com base em atributos como classe, sexo, idade e tarifa.

- A função de ativação utilizada é a **sigmoide**, adequada para problemas de classificação binária.
- A função de perda é o erro quadrático médio (MSE), embora a entropia cruzada seja mais comum em classificações — aqui optamos pela simplicidade.
- O treinamento é feito por 1000 épocas com taxa de aprendizado 0.1.

A rede possui:
- Uma camada de entrada com o mesmo número de neurônios que os atributos de entrada
- Uma camada oculta com 3 neurônios
- Uma camada de saída com 1 neurônio, que retorna a probabilidade de sobrevivência.

"""

import numpy as np
from sklearn.metrics import accuracy_score

# Função de ativação sigmoide e sua derivada
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivada(x):
    return x * (1 - x)

# Estrutura da rede
n_entrada = X_train.shape[1]   # número de atributos
n_oculta = 3                   # número de neurônios na camada oculta
n_saida = 1                    # saída binária (sobreviveu ou não)

# Inicialização dos pesos
np.random.seed(42)
pesos_entrada_oculta = np.random.uniform(-1, 1, (n_entrada, n_oculta))
bias_oculta = np.zeros((1, n_oculta))

pesos_oculta_saida = np.random.uniform(-1, 1, (n_oculta, n_saida))
bias_saida = np.zeros((1, n_saida))

# Hiperparâmetros
epocas = 1000
taxa_aprendizado = 0.1

# Treinamento
for epoca in range(epocas):
    # Forward pass
    entrada_oculta = np.dot(X_train, pesos_entrada_oculta) + bias_oculta
    saida_oculta = sigmoid(entrada_oculta)

    entrada_saida = np.dot(saida_oculta, pesos_oculta_saida) + bias_saida
    saida_final = sigmoid(entrada_saida)

    # Cálculo do erro
    erro = y_train - saida_final

    # Backpropagation
    delta_saida = erro * sigmoid_derivada(saida_final)
    erro_oculta = delta_saida.dot(pesos_oculta_saida.T)
    delta_oculta = erro_oculta * sigmoid_derivada(saida_oculta)

    # Atualização dos pesos e bias
    pesos_oculta_saida += saida_oculta.T.dot(delta_saida) * taxa_aprendizado
    bias_saida += np.sum(delta_saida, axis=0, keepdims=True) * taxa_aprendizado

    pesos_entrada_oculta += X_train.T.dot(delta_oculta) * taxa_aprendizado
    bias_oculta += np.sum(delta_oculta, axis=0, keepdims=True) * taxa_aprendizado

    # Exibir erro ocasionalmente
    if epoca % 100 == 0:
        erro_medio = np.mean(np.abs(erro))
        print(f"Época {epoca} - Erro médio: {erro_medio:.4f}")

# Teste
entrada_oculta_teste = np.dot(X_test, pesos_entrada_oculta) + bias_oculta
saida_oculta_teste = sigmoid(entrada_oculta_teste)

entrada_saida_teste = np.dot(saida_oculta_teste, pesos_oculta_saida) + bias_saida
saida_final_teste = sigmoid(entrada_saida_teste)

# Avaliação
predicoes = (saida_final_teste > 0.5).astype(int)
acuracia = accuracy_score(y_test, predicoes)

print(f"\n🎯 Acurácia no conjunto de teste: {acuracia * 100:.2f}%")

"""## 🛠️ 6. Otimização com GridSearchCV"""

param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [4, 6, 8],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}
grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5)
grid.fit(X_train, y_train)
print("🌟 Melhor combinação de hiperparâmetros:")
print(grid.best_params_)

best_rf = grid.best_estimator_
best_rf_pred = best_rf.predict(X_test)
print("📊 Relatório de classificação (Random Forest ajustado):")
print(classification_report(y_test, best_rf_pred))

"""## 📁 7. Geração do Arquivo de Submissão"""

X_final_test = test_df[feature_columns + ['Sex_male', 'Embarked_Q', 'Embarked_S']]
X_final_test = scaler.transform(X_final_test)

submission = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Survived': best_rf.predict(X_final_test)
})
submission.to_csv('submission.csv', index=False)
print("✅ Arquivo 'submission.csv' gerado com sucesso!")

"""## 📈 8. Visualizações"""

sns.countplot(data=train_df, x='Survived', hue='Pclass')
plt.title("Sobrevivência por Classe")
plt.tight_layout()
plt.show()

"""## ✅ Conclusão
- O modelo Random Forest com hiperparâmetros ajustados obteve uma **acurácia de 81%**.
- O MLPClassifier também apresentou bons resultados, mas com desempenho inferior.
- O arquivo de submissão foi gerado com sucesso e pode ser enviado à plataforma de avaliação.
"""